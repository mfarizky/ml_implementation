# -*- coding: utf-8 -*-
"""Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/mfarizky/ml_implementation/blob/master/BBCA-Stock-Forecasting/Forecasting.ipynb

# Predictive Analytics: BBCA Stock Price Forecasting Using LSTM
___
Oleh [Rijal Farizky](https://github.com/mfarizky)

![bbca](https://github.com/mfarizky/ml_implementation/blob/master/BBCA-Stock-Forecasting/img/bbca.png?raw=1)

## Deskripsi Proyek
Proyek ini bertujuan untuk mengembangkan model machine learning yang mampu memprediksi harga saham BBCA (Bank Central Asia) dengan menggunakan metode *Long Short-Term Memory* (LSTM) dan *Gated Recurrent Unit* (GRU). Prediksi harga saham yang akurat sangat penting bagi investor dan pelaku pasar modal untuk mengambil keputusan investasi yang tepat.

## 1 Import Library
Pada tahap ini kita mendefinisikan seluruh *library* yang akan digunakan untuk dari tahap persiapan hingga evaluasi model.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import math

from matplotlib import cm
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from tensorflow import keras

from statsmodels.tsa.stattools import adfuller

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""## 2. Data Understanding

### 2.1 Data Description

Data Bank Central Asia [(BBCA)](https://www.kaggle.com/datasets/caesarmario/bank-central-asia-stock-historical-price) Stock Historical Price berisi informasi harga saham BBCA (Bank Central Asia) sejumlah 1498 data *time series* mulai dari tanggal 1 Januari 2019 hingga 14 Februari 2025. Data ini mencakup 7 variabel yang memberikan gambaran lengkap tentang aktivitas perdagangan saham BBCA selama periode tersebut.

Berikut adalah penjelasan dari masing-masing variabel dalam data historis harga saham BBCA:
* **Date** : Tanggal harga saham dicatat. [Object/String]
* **Open (Harga Pembukaan):** Harga saham BBCA pada awal hari perdagangan. Ini adalah harga yang disepakati pada saat pasar dibuka. [Float]
* **High (Harga Tertinggi):** Harga saham BBCA tertinggi yang tercapai selama hari perdagangan. [Float]
* **Low (Harga Terendah):** Harga saham BBCA terendah yang tercapai selama hari perdagangan. [Float]
* **Close (Harga Penutupan):** Harga saham BBCA pada akhir hari perdagangan. Ini adalah harga yang disepakati pada saat pasar ditutup. [Float]
* **Adj Close (Harga Penutupan yang Disesuaikan)**: Harga penutupan saham yang telah disesuaikan untuk memperhitungkan Corporate Action  seperti dividen, stock split, dan lainnya. Tujuannya adalah untuk memberikan gambaran yang lebih akurat tentang kinerja saham dari waktu ke waktu. [Float]
* **Volume:** Jumlah saham BBCA yang diperdagangkan selama hari perdagangan. Volume yang tinggi menunjukkan minat yang besar terhadap saham tersebut begitu pula sebaliknya. [Integer]

### 2.2 Data Loading

Memuat dataset yang akan digunakan.
"""

df = pd.read_csv('.\data\BBCA.JK.csv')

"""Dataset akan tampak seperti berikut."""

df.head()

"""Selanjutnya, menemukan informasi dasar yang terdapat pada dataset."""

df.info()

"""Informasi di atas menunjukkan tipe data, jumlah baris dan kolom. Untuk mempermudah proses analisis dan visualisas, kolom `date` diubah tipe datanya menjadi datetime."""

df['Date'] = pd.to_datetime(df['Date'])
print(df['Date'].dtype)

"""## 3. Exploratory Data Analysis

Selanjutnya melakukan proses EDA

### 3.1 Descriptive Analysis
"""

df.describe()

"""Berdasarkan data tersebut, terdapat nilai minimum pada kolom Volume yang bernilai 0. Hal ini bisa disebabkan oleh dua kemungkinan. Pertama, bisa terjadi missing value. Kedua, saham memang tidak diperdagangkan pada tanggal tersebut karena berbagai alasan, seperti hari libur pasar, suspensi perdagangan, atau faktor lainnya. Untuk mengetahuinya kita bisa melakukan visualisasi fitur lainnya pada data dengan volume bernilai 0."""

df[df.Volume == 0]

"""Berdasarkan tabel di atas, pada tanggal tertentu `Open`, `High`, `Low` dan `Close` tidak bergerak sama sekali yang mengindikasikan bahwa pada tanggal tersebut saham tidak diperdagangkan. Hal ini juga menunjukkan bahwa tidak terdapat missing value pada kolom `Volume`.

### Handling Missing & Duplicated Value
"""

df.isnull().sum()

df.duplicated().sum()

"""Tidak terdapat missing value dan duplicate value.

### 3.2 Open and Close Prices of All Time
"""

plt.figure(figsize=(8,6))
plt.plot(df['Date'], df['Open'], label='Open', color='red')
plt.plot(df['Date'], df['Close'], label='Close', color='blue')
plt.title('Open-Close Price Over Time for BBCA Stock Price')
plt.legend()

plt.show()

"""Berdasarkan data tersebut, dapat diamati bahwa harga saham BBCA cenderung mengalami kenaikan tiap tahunnya dan membentuk pola tertentu. Pola ini nantinya dapat dipelajari oleh model deep learning untuk membuat prediksi yang lebih akurat di masa depan.

### 3.3 Trading Volume of All Time

Volume merupakan jumlah total saham yang diperdagangkan dalam satu hari. Hal ini berpengaruh dalam menentukan likuiditas pasar, di mana likuiditas yang tinggi menunjukkan bahwa saham tersebut mudah diperdagangkan tanpa menyebabkan perubahan harga yang signifikan.
"""

plt.figure(figsize=(8,6))
plt.plot(df['Date'], df['Volume'], label='Volume', color='green')
plt.title('Volume Over Time for BBCA Stock Price')
plt.legend()
plt.show()

"""Volume saham yang diperdagangkan cenderung konsisten tiap tahunnya mengindikasikan bahwa saham tersebut memiliki likuiditas yang stabil. Likuiditas yang konsisten menandakan bahwa saham tersebut dapat diperdagangkan dengan mudah oleh investor tanpa menyebabkan perubahan harga yang signifikan, yang merupakan tanda pasar yang sehat dan aktif, meskipun volume saham melonjak cukup tinggi pada periode tertentu.

### 3.4 Yearly Average Movement of Close Feature

**Close** merupakan harga penutupan saham pada akhir hari perdagangan. Harga ini sering digunakan sebagai acuan dalam analisis teknis dan keputusan trading karena mencerminkan nilai terakhir dari saham pada hari tersebut, yang biasanya dianggap lebih penting daripada harga lainnya dalam sehari. Kali ini kita akan melihat pergerakan rata-rata harga penutupan (Close) tiap tahunnya.
"""

df_plot = df.copy()

df_plot['year'] = df_plot.Date.dt.year
df_plot['month'] = df_plot.Date.dt.month

# Defining colors palette
np.random.seed(42)
df_plot = df_plot[['month', 'year', 'Close']].groupby(['month', 'year']).mean()[['Close']].reset_index()
years = df_plot['year'].unique()
cmap = cm.get_cmap('tab10')  # You can choose any colormap you prefer
colors = cmap(np.linspace(0, 1, len(years)))

# Plot
plt.figure(figsize=(10,6))
for i, y in enumerate(years):
    if i > 0:
        plt.plot('month', 'Close', data=df_plot[df_plot['year'] == y],color=colors[i], label=y)
        if y == 2018:
            plt.text(df_plot.loc[df_plot.year==y, :].shape[0]+0.3, df_plot.loc[df_plot.year==y, 'Close'][-1:].values[0], y, fontsize=12, color=colors[i])
        else:
            plt.text(df_plot.loc[df_plot.year==y, :].shape[0]+0.1, df_plot.loc[df_plot.year==y, 'Close'][-1:].values[0], y, fontsize=12, color=colors[i])

# Setting labels
plt.gca().set(ylabel= 'Close', xlabel = 'Month')
plt.xticks(ticks=range(1, 13), labels=range(1, 13), fontsize=12, alpha=0.7)
plt.yticks(fontsize=12, alpha=.7)
plt.title("Close - Yearly Average Movement", fontsize=20)
plt.ylabel('Close')
plt.xlabel('Month')
plt.show()

"""Berdasarkan plot di atas, dapat dilihat bahwa pergerakan saham cenderung memiliki pola tertentu dan cukup konsisten tiap tahunnya. Meskipun terdapat fluktuasi bulanan, saham cenderung menunjukkan tren kenaikan dari tahun ke tahun.

### 3.5 Numerical Feature Correlation
Selanjutnya, kita akan menganalisi `Numerical Feature Correlation`untuk mengetahui hubungan antara fitur-fitur numerik dalam data. Kita akan melakukan visualisasi hubungan antar fitur numerik dengan pair plot kemudian menghitung korelasi matriks untuk mendapatkan gambaran lengkap tentang hubungan antar semua fitur numerik.
"""

plt.figure(figsize=(8, 6))
sns.pairplot(df, diag_kind='kde')
plt.show()

"""Visualisasi di atas menunjukkan terdapat korelasi postif antar fitur `Open`, `High`, `Low`, `Close`, `Adj. Close`. Selanjutnya menghitung korelasi matrix."""

plt.figure(figsize=(8,6))
correlation_matrix = df.corr()

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title(f"Matriks Korelasi untuk Fitur Numerik ", size=20)

"""Sama seperti visualisasi sebelumnya, korelasi antar fitur `Open`, `High`, `Low`, `Close`, `Adj. Close` **bernilai 1** yang menunjukkan korelasi positif sempurna.

## 4. Data Preparation

### 4.1 Feature Engineering - Feature Selection

Berdasarkan hasil analisis, fitur `Open`, `High`, `Low`, `Close`, `Adj. Close` berkorelasi positif sempurna yang berarti satu perubahan akan saling memengaruhi, maka kita bisa memilih salah satu fitur tersebut untuk digunakan dalam membangun Model Deep Learning. Dalam hal ini, kita akan menggunakan fitur `Close`.
"""

df['Close'].head()

stock_close = df['Close'].values

stock_close

"""### 4.2 Standarisasi Data

Data dinormalisasi dengan metode standarisasi.
"""

scaler = StandardScaler()
data = scaler.fit_transform(stock_close.reshape(-1,1))

"""### 4.3 Splitting Data to Train & Test

Pada tahap ini, kita akan membagi data menjadi data pelatihan (train) dan data pengujian (test). Sebelum melakukannya, kita akan mendefinisikan variabel dan fungsi yang akan digunakan untuk pembagian data dan pembuatan *window*. *Window* ini merupakan sekumpulan data dalam interval waktu tertentu yang digunakan untuk membuat prediksi *time series*.
"""

WINDOW_SIZE = 60
BATCH_SIZE = 32
TRAIN_RATIO = 0.9

def create_windowed_features(data, window_size):
    X = []
    y = []
    for i in range(window_size, data.shape[0]):
        X.append(data[i-window_size:i])
        y.append(data[i])
    return np.array(X), np.array(y)

def split_features_and_target(df, train_ratio=TRAIN_RATIO, window_size=WINDOW_SIZE):
    train_data = df[:int(len(df) * train_ratio)]
    test_data = df[int(len(df) * train_ratio) - window_size:]
    print("Training data:", train_data.shape)
    print("Test data:", test_data.shape)
    X_train, y_train = create_windowed_features(train_data, window_size)
    X_test, y_test = create_windowed_features(test_data, window_size)

    return X_train, y_train, X_test, y_test

X_train, y_train, X_test, y_test = split_features_and_target(data)

# After windowing or feature extraction step
print("Training features shape after windowing:", X_train.shape)
print("Training labels shape:", y_train.shape)
print("Testing features shape after windowing:", X_test.shape)
print("Testing labels shape:", y_test.shape)

"""## 5. Model Development

Pada tahap ini, kita akan membangun model LSTM dan GRU dengan parameter yang sama. Berikut adalah konfigurasi model yang akan kita gunakan:
* EPOCHS : 20
* Hidden Layer : 128 unit
* Activation Function : Adam
* Look Back Value / Window : 60
* Dropout : 0.2

### 5.1 LSTM
"""

model_lstm = keras.models.Sequential()
model_lstm.add(keras.layers.LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model_lstm.add(keras.layers.Dense(units=128, activation='relu'))
model_lstm.add(keras.layers.LSTM(units=64, return_sequences=False))
model_lstm.add(keras.layers.Dropout(0.2))
model_lstm.add(keras.layers.Dense(units=1))

model_lstm.summary()

model_lstm.compile(optimizer='adam',
              loss='mae',
              metrics=keras.metrics.RootMeanSquaredError())

history_lstm = model_lstm.fit(X_train, y_train,
               epochs=20,
               batch_size=32,
               validation_data=(X_test, y_test),
               callbacks=[tensorboard_callback_lstm]
               )

"""### 5.2 GRU"""

model_gru = keras.models.Sequential()

model_gru.add(keras.layers.GRU(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model_gru.add(keras.layers.Dense(units=128, activation='relu'))
model_gru.add(keras.layers.GRU(units=64, return_sequences=False))
model_gru.add(keras.layers.Dropout(0.2))
model_gru.add(keras.layers.Dense(units=1))

model_gru.summary()

history_gru = model_gru.fit(X_train, y_train,
               epochs=20,
               batch_size=32,
               validation_data=(X_test, y_test),
               callbacks=[tensorboard_callback_gru])

"""## 6. Evaluasi Model

### 6.1 Compare train loss and validation loss
"""

def plot_loss(history, model_name, ax):
    ax.plot(history.history['loss'], label='Train Loss')
    ax.plot(history.history['val_loss'], label='Validation Loss')
    ax.set_title(f'{model_name} Model Loss')
    ax.set_xlabel('Epochs')
    ax.set_ylabel('Loss')
    ax.legend()

# Membuat dua plot loss secara berdampingan
fig, axs = plt.subplots(1, 2, figsize=(16, 9))
plot_loss(history_lstm, 'LSTM', axs[0])
plot_loss(history_gru, 'GRU', axs[1])
plt.tight_layout()
plt.show()

"""### 6.2 Compare prediction vs test data

#### 6.2.1 Predict the Data
"""

def prediction(model,data):
    prediction = model.predict(data)
    prediction = scaler.inverse_transform(prediction)
    return prediction

predictions_lstm = prediction(model_lstm, X_test)
predictions_gru = prediction(model_gru, X_test)

"""#### 6.2.2 Plotting Prediction Result"""

def plot_future(prediction, model_name, ax, start_date = '2024-01-01'):
        train_data = df[:int(len(df) * TRAIN_RATIO)]
        test_data = df[int(len(df) * TRAIN_RATIO):]

        ax.plot(train_data['Date'][train_data.Date >= start_date],
                train_data['Close'][train_data.Date >= start_date],
                label='Train (Actual)',
                color='blue')
        ax.plot(test_data['Date'], test_data['Close'], label='Test (Actual)', color='green')
        ax.plot(test_data['Date'], prediction, label=f'{model_name} (Predictions)', color='orange')
        ax.set_title(f'Prediction vs Test data {model_name} Model')
        ax.set_xlabel('Date')
        ax.set_ylabel('Close Price')
        ax.legend()

# Membuat dua plot loss secara berdampingan
fig, axs = plt.subplots(1, 2, figsize=(16, 9))
plot_future(predictions_lstm, 'LSTM', axs[0])
plot_future(predictions_gru, 'GRU', axs[1])
plt.tight_layout()
plt.show()

"""### 6.3 Compare Evaluation Metric"""

def evaluate_prediction(predictions, actual, model_name,df):
    errors = predictions - actual
    mse = np.square(errors).mean()
    rmse = np.sqrt(mse)
    mae = np.abs(errors).mean()
    mape = np.mean(np.abs(errors / actual)) * 100
    rsmpe = np.sqrt(np.mean((errors / actual) ** 2)) * 100

    df = df.append({
        'Model': model_name,
        'MAE': mae,
        'RMSE': rmse,
        'MAPE': mape,
        'RSMPE': rsmpe
    }, ignore_index=True)
    return df

y_test_inversed = scaler.inverse_transform(y_test)

evaluation_df = pd.DataFrame(columns=['Model', 'MAE', 'RMSE', 'MAPE', 'RSMPE'])

evaluation_df = evaluate_prediction(predictions_lstm, y_test_inversed, 'LSTM', evaluation_df)
evaluation_df = evaluate_prediction(predictions_gru, y_test_inversed, 'GRU', evaluation_df)
evaluation_df.set_index('Model', inplace=True)
evaluation_df